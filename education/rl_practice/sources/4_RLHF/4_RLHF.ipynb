{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a0179dc",
      "metadata": {
        "id": "9a0179dc"
      },
      "source": [
        "# Reinforcement Learning with Human Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be450341",
      "metadata": {
        "id": "be450341"
      },
      "source": [
        "## Problem Definition \n",
        "\n",
        "With the foundation of classical reinforcement learning (RL) covered, this chapter takes a step towards training intelligent agents that are capble of adapting their behaviour as per the human user. Classical RL aims to train an agent to learn a function defining specific behaviour based on a certain policy while iteratively maximizing the rewards achievable given the agent's performance. However, this situation requires an explicit definition of the reward function while also creating complexity for dynamic adaptation. In many real-world scenarios, the ground truth may be subjective (i.e. not absolutely defined) E.g. the perception of an aggressive question may be different for each human user. Situation as such calls for the need to align models that can adapt to the human user's personal perception over offerring generic solutions.\n",
        "\n",
        "Reinforcement Learning with Human Feedback (RLHF) is one way to address this problem by training the reward function directly from acquired human feedback, to align the model with human expectations given the situation, context and the human's perception. In RLHF, we start with a pre-trained model that is tested for specific results. This model then serves as the baseline to re-train using feedback and improve an agent's policy via an optimization algorithm (e.g. proximal policy optimization). Some of the most famous and widely used applications of RLHF are generative AI, large language models (LLMs), e.g. Chatgpt etc. The base of these generative AI applications is feedback training on supervised pre-trained models that are then optimized to meet the human user's goals. The figure below provides an overview of RLHF vs Classical RL where the introduction of human feedback into the training loop allows the agent to add wieghts (relevance and priorty) as per user's personalization.\n",
        "\n",
        "<!-- ![Basic RLHF vs RL](Images/RLHF_Base.png) -->\n",
        "```{image} Images/RLHF_Base.png\n",
        ":width: 500px\n",
        ":name: RLHF_Base\n",
        "```\n",
        "\n",
        "In this notebook we present a practical implementation of **RLHF aimed at aligning a generative model (GPT-2) to produce more positive movie reviews**. It uses the **IMDB dataset** for movie reviews and a comparision between standard GPT-2 versus RLHF-trained GPT-2 to see the impact of feedback. Within this example, we will use the BERT reward model for sentiment analysis and a Proximal Policy Optimization (PPO) condition approach for RL training.  \n",
        "\n",
        "\n",
        "Before diving into RLHF, we first need to introduce certain concents about LLMs and have a brief overview of the RLHF training procedure. \n",
        "\n",
        "### What is a Large Language Model (LLM)? \n",
        "- In simplest terms, a language model is a type of machine learning model trained to generate a probability distribution of words relative to the environment. An LLM is a larger and juiced up version with millions of tuning parameters and variables used to work with languages. To progress further, we need to recap a basic understanding of how natural language processing (NLP) works for prediction tasks. Prior to 2016, language models interpretted words and sentences by processing word after word. While in 2017, the engineers at google presented the concept of transformers {cite}`vaswani2017attention`. The **Token** is the numeric representation of a word, set of characters or sentences when processed as a block. The following Figure showcases the approach of LLMs when analyzed using transformers. \n",
        "\n",
        "![Tokenization](Images/Tokenization.png)\n",
        "\n",
        "### What are Transformers?\n",
        "-Transformers are a state-of-the-art architecture that computes text as tokens and converts by converting it into a vector along a embeddings table that stores the relative context of text with respect to the environment. It was introduced by google engineers in the paper {cite}`vaswani2017attention`, where attention denotes the relative importance (i.e. weightage) of each component (text) in a sequence relative to the other components in that specific sequence. Transformers are widely used as part of languge model applications for translation, prediciton etc. One of the most notable changes in LLMs with the introduction of transformers, were its ability to read complete texts in parallel. Words assocoated with numbers as vector are more efficient to tune across multi dimension matrices describing the attention (i.e. relevance or weightage) of the words within the given texts. The Figure below provides an overview of a simple case where, given a sentence to complete, the LLM sweeps through its vast training to extract probablities of the upcoming words relative to the given sentence. \n",
        "\n",
        "![Transformers_LLMs](Images/Example_LLM.png)\n",
        "\n",
        "## Implementation\n",
        "\n",
        "In this chapter, we focus on a task that aims to include human feedback into the training process of an LLM and then observe the difference before and after human feedback. We will be using a movie review data set called IMDB, a pre-trained generative model (gpt2) on the IMDB, a BERT (Bidirectional Encoder Representations from Transformers) to finetune the model on IMDB data for sentinment analysis and RL via Proximal policy optimization. In the general ChatGPT (Generative pre-trained transformer) model training, the steps followed were as such:\n",
        "\n",
        "1. Supervised fine-tuning - (SFT). Supervised fine-tuning of a previously trained language model (LM) on the first type of labeled data - with ready-made answers.\n",
        "\n",
        "2. Reward model. Training a reward model on the second type of data - people ranking different bot responses.\n",
        "\n",
        "3. Reinforcement learning - RL. Using a reward model to retrain a language model (LM) using reinforcement learning (RL) .\n",
        "\n",
        "These steps are repeated for multiple iterations to finally build a reward function that models human preferences {cite}`ouyang2022training`.\n",
        "\n",
        "![ChatGPT_Approach](Images/chatgpt_diagram_dark.png)\n",
        "Figure source: https://openai.com/index/chatgpt/\n",
        "\n",
        "\n",
        "In order to train models, we use Proximal policy optimization (PPO) approach. A reinforcement learning (RL) algorithm for training an intelligent agent via a policy gradient method. We use this approach to ensure that the over-training & over fitting do not occur.  The outcomes of such a step is to prevent bias in the results.\n",
        "\n",
        "\n",
        "### Intialization\n",
        "\n",
        "We first install and load libraries that we wil be using throughout this chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a7da53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "81a7da53",
        "outputId": "629af531-1f17-4506-90db-7e1a8be8e25a"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install datasets==2.15.0\n",
        "!pip install peft==0.5.0\n",
        "!pip install trl==0.11.3\n",
        "!pip install --no-binary numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068df1e3",
      "metadata": {
        "id": "068df1e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, GPT2LMHeadModel, pipeline\n",
        "from trl.core import LengthSampler\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
        "\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f2167ad",
      "metadata": {
        "id": "5f2167ad",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "### Intializing the Pre-trained model on IMDB data\n",
        "\n",
        "Here we setup our PPO RL training conditions with a learning rate (LR) and a base for logging weights of the transformer during training. Here, we use \"wandb\" for its simplcity in usage.\n",
        "\n",
        "Source: https://huggingface.co/lvwerra/gpt2-imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0a6dc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae0a6dc0",
        "outputId": "dc8c8cf4-b24a-4c6a-c34a-6227dd8a6626"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "config = PPOConfig(\n",
        "    model_name=\"lvwerra/gpt2-imdb\",\n",
        "    learning_rate=1.5e-5,\n",
        "    log_with=\"wandb\")\n",
        "\n",
        "# Argument to be sent to Sentiment model\n",
        "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b6f760",
      "metadata": {
        "id": "87b6f760"
      },
      "source": [
        "### Creating a wandb instance to log Weights\n",
        "\n",
        "\n",
        "Here, you will be asked to open the website and create an account/log in to acquire your api. The steps are as follow:\n",
        "\n",
        "1. Go to: [wandb](https://wandb.ai/login) and create an account/log in using existing accounts.\n",
        "2. Next, go to [Authorize Wandb to create API](https://wandb.ai/authorize), here you will see a dashboard with your API key\n",
        "3. Copy and paste this API into the instance below as show in the image\n",
        "\n",
        "![Usage of Weights and Biases](Images/WB_Usage.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027c2a24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "027c2a24",
        "outputId": "a163c0aa-75b1-45b0-a379-12f51b9e11c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mash-dadaya\u001b[0m (\u001b[33mash-dadaya-hse-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250427_174334-957nno8a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a' target=\"_blank\">earthy-serenity-8</a></strong> to <a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7eae22adcf90>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c431c95",
      "metadata": {
        "id": "7c431c95",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "This IMDB dataset contains 50,000 reviews of movies labelled with positive or negative feedback. We load this data, filter to include reviews that are greater than 250 words and tokenize the text.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f21e5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78f21e5d",
        "outputId": "18650bde-ae76-4bd2-f6c6-fa598bbda0c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def tokenize_data(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        dataset_name (`str`):\n",
        "            The name of the dataset to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        dataloader (`torch.utils.data.DataLoader`):\n",
        "            The dataloader for the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Load imdb dataset\n",
        "    dfs = load_dataset(dataset_name, split=\"train\")\n",
        "    dfs = dfs.rename_columns({\"text\": \"review\"})\n",
        "    dfs = dfs.filter(lambda x: len(x[\"review\"]) > 250, batched=False)\n",
        "\n",
        "    input_size_txt = LengthSampler(input_min_text_length, input_max_text_length)\n",
        "\n",
        "    def tokenize(sample):\n",
        "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size_txt()]\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    dfs = dfs.map(tokenize, batched=False)\n",
        "    dfs.set_format(type=\"torch\")\n",
        "    return dfs\n",
        "\n",
        "dataset = tokenize_data(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5eb331",
      "metadata": {
        "id": "5a5eb331"
      },
      "outputs": [],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e8ba8f",
      "metadata": {
        "id": "38e8ba8f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "### Load gpt2 model\n",
        "\n",
        "We load the gpt2 model as two instances as a:\n",
        "1. Trained version (Optimized)\n",
        "2. Reference version (Original)\n",
        "\n",
        "to observe the difference in performance with feedback as a factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8160297d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8160297d",
        "outputId": "6dd7feda-66fd-4308-a546-eaf9b47947be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(config.model_name)\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1)\n",
        "\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "\n",
        "new_model = AutoModelForCausalLMWithValueHead.from_pretrained(peft_model, is_trainable=True)\n",
        "\n",
        "original_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1838cf1e",
      "metadata": {
        "id": "1838cf1e"
      },
      "source": [
        "### Creating instances of BERT Classfied to fine tune the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885b94b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "885b94b0",
        "outputId": "e78c0d01-f028-4b30-eec7-024af8851bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earthy-serenity-8</strong> at: <a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/uncategorized/runs/957nno8a</a><br> View project at: <a href='https://wandb.ai/ash-dadaya-hse-university/uncategorized' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/uncategorized</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250427_174334-957nno8a/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250427_174354-cslh4uuq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ash-dadaya-hse-university/trl/runs/cslh4uuq' target=\"_blank\">fluent-cosmos-7</a></strong> to <a href='https://wandb.ai/ash-dadaya-hse-university/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ash-dadaya-hse-university/trl' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/trl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ash-dadaya-hse-university/trl/runs/cslh4uuq' target=\"_blank\">https://wandb.ai/ash-dadaya-hse-university/trl/runs/cslh4uuq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "ppo_trainer = PPOTrainer(\n",
        "    config, new_model, original_model, tokenizer, dataset=dataset, data_collator=collator)\n",
        "\n",
        "\n",
        "src_device = ppo_trainer.accelerator.device\n",
        "if ppo_trainer.accelerator.num_processes == 1:\n",
        "    src_device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
        "sentiment_pipe = pipeline(\n",
        "    \"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=src_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54ce039",
      "metadata": {
        "id": "e54ce039"
      },
      "source": [
        "### Mini Visualizaiton\n",
        "\n",
        "Here, we show the sentimental output for either types of reviews as probablities. i.e. Positive and negative logits to represent the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a9c23f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6a9c23f",
        "outputId": "034b8eb6-9c9f-4dd4-d897-0c8d66811709"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[{'label': 'NEGATIVE', 'score': 2.335048198699951},\n",
              "  {'label': 'POSITIVE', 'score': -2.7265758514404297}]]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_1 = \"this movie was really bad!!\"\n",
        "sentiment_pipe(test_1, **sent_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba8709f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ba8709f",
        "outputId": "522fb66e-0111-4322-ec23-8f748e37814a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'NEGATIVE', 'score': -2.496453285217285},\n",
              "  {'label': 'POSITIVE', 'score': 2.7821977138519287}]]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_2 = \"It was an amazing movie\"\n",
        "sentiment_pipe(test_2, **sent_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96bd352a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96bd352a",
        "outputId": "372e9cd6-6e0d-4fb8-9aa2-98c0dee92ea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'label': 'NEGATIVE', 'score': 1.2481341361999512},\n",
              "  {'label': 'POSITIVE', 'score': -1.6977636814117432}]]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_3 = \"I threw up at by finale of the movie\"\n",
        "sentiment_pipe(test_3, **sent_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14420213",
      "metadata": {
        "id": "14420213"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9087af",
      "metadata": {
        "id": "ea9087af"
      },
      "source": [
        "Here, we aim to train the model in the following steps similar to how an MDP is traverssed:\n",
        "\n",
        "The **Query** is considered as the state of the system (S), the **response** is the action (A) taken when in state (S) and reward (R) is achieved with this tuple\n",
        "\n",
        "1. Acquire responses from gpt-2 model\n",
        "2. Acquire sentiment from BERT\n",
        "3. Optimze the policy via PPO using (query, response, reward)\n",
        "\n",
        "When run on Google Colab, this snippet of code takes around 35 - 40 mins to complete 12 steps of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xVMzm1sVXBWO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVMzm1sVXBWO",
        "outputId": "6f9d9238-5a95-4919-f027-8dc792d2e97f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 0.0\n",
            "ppo/returns/mean: [0.7363893]\n",
            "ppo/policy/advantages_mean: [8.384737e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [09:18, 276.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.00028980534989386797\n",
            "ppo/returns/mean: [0.50014883]\n",
            "ppo/policy/advantages_mean: [5.362319e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r3it [13:46, 273.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.0018314942717552185\n",
            "ppo/returns/mean: [0.2460297]\n",
            "ppo/policy/advantages_mean: [2.1364782e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r4it [18:25, 275.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.001931782579049468\n",
            "ppo/returns/mean: [0.51561016]\n",
            "ppo/policy/advantages_mean: [4.4654787e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r5it [23:02, 276.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.0013388340594246984\n",
            "ppo/returns/mean: [0.7350349]\n",
            "ppo/policy/advantages_mean: [-6.260703e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r6it [27:41, 276.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 0.0016613180050626397\n",
            "ppo/returns/mean: [0.55383056]\n",
            "ppo/policy/advantages_mean: [-1.1246533e-07]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r7it [32:12, 275.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.005873559974133968\n",
            "ppo/returns/mean: [0.48312318]\n",
            "ppo/policy/advantages_mean: [2.483527e-09]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r8it [36:43, 273.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.004583868198096752\n",
            "ppo/returns/mean: [0.35332435]\n",
            "ppo/policy/advantages_mean: [4.4592003e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r9it [41:11, 272.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.006592849735170603\n",
            "ppo/returns/mean: [0.44370276]\n",
            "ppo/policy/advantages_mean: [-7.629787e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [45:44, 274.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -0.005800541490316391\n",
            "ppo/returns/mean: [0.56546915]\n",
            "ppo/policy/advantages_mean: [2.091391e-08]\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output_min_length = 4     # The minimum number of tokens for each model response\n",
        "output_max_length = 16    # The maximum number of tokens for each model response\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)  # Sampling between the min-max length\n",
        "\n",
        "\n",
        "gen_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    }\n",
        "\n",
        "num_steps = 12 # Number of training steps w.r.t PPO\n",
        "\n",
        "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    if epoch >= num_steps:\n",
        "        break\n",
        "\n",
        "    query_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # Acquire response from gpt2\n",
        "    response_tensors = []\n",
        "    for query in query_tensors:\n",
        "        gen_len = output_length_sampler()\n",
        "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
        "        response_tensors.append(response.squeeze()[-gen_len:])\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "    # Sentiment computation score\n",
        "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
        "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
        "\n",
        "    # PPO looping steps\n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
        "    print(\"-\".join(\"\" for x in range(100)))\n",
        "\n",
        "    ppo_trainer.log_stats(stats, batch, rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75acecfd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "75acecfd",
        "outputId": "7214a4ca-3659-42d7-bac9-7e5dc9dc496d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Yes I admit I cried during this\",\n          \"I generally find Loretta Young\",\n          \"This film can\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response (before)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" one, I'm while the truck flipped.)<\",\n          \" a signifier. Her writing is always very poor, especially when\",\n          \"'t lie in any way, it's all\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response (after)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" last viewing.<br /><br />I truly\",\n          \"'s stuff pretty restrained and dark, for instance.<br /><\",\n          \" effortlessly tell the difference. The acting is great\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewards (before)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8354729786910449,\n        \"min\": -2.9148647785186768,\n        \"max\": 2.5097267627716064,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          -0.6085107326507568,\n          -2.4045450687408447,\n          0.5979214310646057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewards (after)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.968970359311931,\n        \"min\": -2.8849434852600098,\n        \"max\": 2.7452423572540283,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.951698660850525,\n          1.521146535873413,\n          2.7452423572540283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cd176fbd-7a3a-4392-84a8-defe719dd6ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response (before)</th>\n",
              "      <th>response (after)</th>\n",
              "      <th>rewards (before)</th>\n",
              "      <th>rewards (after)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes I admit I cried during this</td>\n",
              "      <td>one, I'm while the truck flipped.)&lt;</td>\n",
              "      <td>last viewing.&lt;br /&gt;&lt;br /&gt;I truly</td>\n",
              "      <td>-0.608511</td>\n",
              "      <td>1.951699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I generally find Loretta Young</td>\n",
              "      <td>a signifier. Her writing is always very poor,...</td>\n",
              "      <td>'s stuff pretty restrained and dark, for insta...</td>\n",
              "      <td>-2.404545</td>\n",
              "      <td>1.521147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This was a disappointing</td>\n",
              "      <td>film. I've gotta</td>\n",
              "      <td>film. It didn't</td>\n",
              "      <td>-2.847512</td>\n",
              "      <td>-2.773234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is</td>\n",
              "      <td>much more than to say it's a thriller, it is a</td>\n",
              "      <td>one of Lois Torrence's best films, at least. ...</td>\n",
              "      <td>2.057177</td>\n",
              "      <td>2.635111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An old man</td>\n",
              "      <td>hit by what might</td>\n",
              "      <td>managed to make an</td>\n",
              "      <td>-0.880338</td>\n",
              "      <td>-0.953584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This film can</td>\n",
              "      <td>'t lie in any way, it's all</td>\n",
              "      <td>effortlessly tell the difference. The acting ...</td>\n",
              "      <td>0.597921</td>\n",
              "      <td>2.745242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I saw this movie about 5</td>\n",
              "      <td>or 6 yrs</td>\n",
              "      <td>times after I picked</td>\n",
              "      <td>0.048315</td>\n",
              "      <td>1.311543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Spike Lee has been</td>\n",
              "      <td>around a long enough</td>\n",
              "      <td>as bad as it</td>\n",
              "      <td>0.642214</td>\n",
              "      <td>-2.094339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I saw this film</td>\n",
              "      <td>, just dumb....not from the censors, but anyway!</td>\n",
              "      <td>at a film festival; the actors/actresses befo...</td>\n",
              "      <td>-1.926696</td>\n",
              "      <td>1.342419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I have to agree</td>\n",
              "      <td>that these characters are just wasted. Eviden...</td>\n",
              "      <td>that the book in the 80's is so tasteless</td>\n",
              "      <td>-2.914865</td>\n",
              "      <td>-1.551304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Thoughtless, ignorant, ill</td>\n",
              "      <td>-informed, godless</td>\n",
              "      <td>-conceived, week</td>\n",
              "      <td>-2.656834</td>\n",
              "      <td>-2.884943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Dark Rising is</td>\n",
              "      <td>also a spoiler and badly directed graphic nov...</td>\n",
              "      <td>by my standard (Max Dillon's latest film), bu...</td>\n",
              "      <td>-2.908494</td>\n",
              "      <td>-1.567007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mobile Suit Gundam Wing is the</td>\n",
              "      <td>best Gundam yet for the mastering of this mas...</td>\n",
              "      <td>most up to date animation of all time. As is ...</td>\n",
              "      <td>2.509727</td>\n",
              "      <td>2.041152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Why is it that everyone who</td>\n",
              "      <td>lives in the mostly swanky club</td>\n",
              "      <td>believes fake news today seems to be</td>\n",
              "      <td>-0.154455</td>\n",
              "      <td>-0.837222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I wish more movies were</td>\n",
              "      <td>made of this kind, so we can all watch this m...</td>\n",
              "      <td>like that than Roskin'. He's lucky to direct ...</td>\n",
              "      <td>1.649065</td>\n",
              "      <td>1.155018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Great CGI effects &amp;</td>\n",
              "      <td>special effects and nothing just</td>\n",
              "      <td>Covering.3 Disney</td>\n",
              "      <td>-0.286802</td>\n",
              "      <td>1.571842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd176fbd-7a3a-4392-84a8-defe719dd6ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd176fbd-7a3a-4392-84a8-defe719dd6ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd176fbd-7a3a-4392-84a8-defe719dd6ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df690c96-d6f3-481d-bb28-b0549a655139\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df690c96-d6f3-481d-bb28-b0549a655139')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df690c96-d6f3-481d-bb28-b0549a655139 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5256aa19-e9ce-4f2b-80f0-ecdb972c9626\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5256aa19-e9ce-4f2b-80f0-ecdb972c9626 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                              query  \\\n",
              "0   Yes I admit I cried during this   \n",
              "1    I generally find Loretta Young   \n",
              "2          This was a disappointing   \n",
              "3                           This is   \n",
              "4                        An old man   \n",
              "5                     This film can   \n",
              "6          I saw this movie about 5   \n",
              "7                Spike Lee has been   \n",
              "8                   I saw this film   \n",
              "9                   I have to agree   \n",
              "10       Thoughtless, ignorant, ill   \n",
              "11                   Dark Rising is   \n",
              "12   Mobile Suit Gundam Wing is the   \n",
              "13      Why is it that everyone who   \n",
              "14          I wish more movies were   \n",
              "15              Great CGI effects &   \n",
              "\n",
              "                                    response (before)  \\\n",
              "0                 one, I'm while the truck flipped.)<   \n",
              "1    a signifier. Her writing is always very poor,...   \n",
              "2                                    film. I've gotta   \n",
              "3      much more than to say it's a thriller, it is a   \n",
              "4                                   hit by what might   \n",
              "5                         't lie in any way, it's all   \n",
              "6                                            or 6 yrs   \n",
              "7                                around a long enough   \n",
              "8    , just dumb....not from the censors, but anyway!   \n",
              "9    that these characters are just wasted. Eviden...   \n",
              "10                                 -informed, godless   \n",
              "11   also a spoiler and badly directed graphic nov...   \n",
              "12   best Gundam yet for the mastering of this mas...   \n",
              "13                    lives in the mostly swanky club   \n",
              "14   made of this kind, so we can all watch this m...   \n",
              "15                   special effects and nothing just   \n",
              "\n",
              "                                     response (after)  rewards (before)  \\\n",
              "0                    last viewing.<br /><br />I truly         -0.608511   \n",
              "1   's stuff pretty restrained and dark, for insta...         -2.404545   \n",
              "2                                     film. It didn't         -2.847512   \n",
              "3    one of Lois Torrence's best films, at least. ...          2.057177   \n",
              "4                                  managed to make an         -0.880338   \n",
              "5    effortlessly tell the difference. The acting ...          0.597921   \n",
              "6                                times after I picked          0.048315   \n",
              "7                                        as bad as it          0.642214   \n",
              "8    at a film festival; the actors/actresses befo...         -1.926696   \n",
              "9           that the book in the 80's is so tasteless         -2.914865   \n",
              "10                                   -conceived, week         -2.656834   \n",
              "11   by my standard (Max Dillon's latest film), bu...         -2.908494   \n",
              "12   most up to date animation of all time. As is ...          2.509727   \n",
              "13               believes fake news today seems to be         -0.154455   \n",
              "14   like that than Roskin'. He's lucky to direct ...          1.649065   \n",
              "15                                  Covering.3 Disney         -0.286802   \n",
              "\n",
              "    rewards (after)  \n",
              "0          1.951699  \n",
              "1          1.521147  \n",
              "2         -2.773234  \n",
              "3          2.635111  \n",
              "4         -0.953584  \n",
              "5          2.745242  \n",
              "6          1.311543  \n",
              "7         -2.094339  \n",
              "8          1.342419  \n",
              "9         -1.551304  \n",
              "10        -2.884943  \n",
              "11        -1.567007  \n",
              "12         2.041152  \n",
              "13        -0.837222  \n",
              "14         1.155018  \n",
              "15         1.571842  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#To interpret results, we create a script to generate and evaluate sentimate of respones across old and new models\n",
        "\n",
        "batch_size = 18 # Number of queries o take as input\n",
        "game_data = dict()\n",
        "dataset.set_format(\"pandas\")\n",
        "\n",
        "# Random sampling of data\n",
        "df_batch = dataset[:].sample(batch_size)\n",
        "\n",
        "# We store queries as string lists\n",
        "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
        "query_tensors = df_batch[\"input_ids\"].tolist()\n",
        "\n",
        "\n",
        "# To store final resulting outputs\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "\n",
        "# Acquiring respones from Original model and Newly trained model\n",
        "for i in range(batch_size):\n",
        "    gen_len = output_length_sampler()\n",
        "    output = original_model.generate(\n",
        "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(src_device),\n",
        "        max_new_tokens=gen_len,\n",
        "        **gen_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    response_tensors_ref.append(output)\n",
        "    output = new_model.generate(\n",
        "        input_ids=torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(src_device),\n",
        "        max_new_tokens=gen_len,\n",
        "        **gen_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    response_tensors.append(output)\n",
        "\n",
        "\n",
        "# Recover the text from given tokenized vector\n",
        "game_data[\"response (before)\"] = [\n",
        "    tokenizer.decode(response_tensors_ref[i]) for i in range(batch_size)\n",
        "]\n",
        "game_data[\"response (after)\"] = [\n",
        "    tokenizer.decode(response_tensors[i]) for i in range(batch_size)\n",
        "]\n",
        "\n",
        "# Sentiment analysis of query-response pairs before feedback training\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
        "game_data[\"rewards (before)\"] = [\n",
        "    output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)\n",
        "]\n",
        "\n",
        "# Sentiment analysis of query-response pairs after feedback training via PPO RL\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
        "game_data[\"rewards (after)\"] = [\n",
        "    output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)\n",
        "]\n",
        "\n",
        "# Visualization of the results\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Q5RjHK3j3Dh",
      "metadata": {
        "id": "_Q5RjHK3j3Dh"
      },
      "source": [
        "When going through the results dataframe in detail. We can see multiple instances where the completed query before human feedback is more blatant and non positively encouraging. However, in the feedback-trained model, we can see the respones becoming more positive and encouraging. \n",
        "\n",
        "e.g. \n",
        "                          \n",
        "1. Query: I have to agree _____\n",
        "- Response (before feedback): **\"that these characters are just wasted.\"**\n",
        "- Response (after feedback) : **\"that the book in the 80's is so tasteles\"**\n",
        "\n",
        "\n",
        "\n",
        "2. Query: This is ...\n",
        "- Response (before feedback): **\"much more than to say it's a thriller, it is a\"**\n",
        "- Response (after feedback) : **\"one of Lois Torrence's best films, at least.\"**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70bb4f11",
      "metadata": {
        "id": "70bb4f11",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "Overall, within this chapter we study the foundations of LLMs, transformers and the concept of having human feedback included into the training process via reiforcement learning. Using an experiment to re-train an RL model to propose more positive reviews of movies from the IMDB. We see the result showing difference between the base gpt2 model versus the human feedback trained model. However, it is worth noting that despite the expanding applications of RLHF from text summarizations to computer vision etc, they still face challenges due to their training and data colleciton approaches which together impacts the performance of the models, by creating bias, hallucinations etc. There are still debates and dilemmas about whether a model is as good as its data or whether retraining is the key to better performance but this extends into a research question on its own. \n",
        "\n",
        "You can also check out the gpt-2 model trained on IMDB dataset aiming to give neutral reviews (https://huggingface.co/mrm8488/gpt2-imdb-neutral). "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
